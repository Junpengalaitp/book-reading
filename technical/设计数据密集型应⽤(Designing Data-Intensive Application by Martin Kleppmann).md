# 第一部分
* 数据密集型应用设计的基本思想

## 第一章 可靠性、可扩展性、可维护性
* 数据密集型应用通常由提供通用功能的标准组件构建而成
  * 存储数据: 数据库
  * 减少昂贵操作的次数：缓存
  * 搜索、过滤数据：搜索索引
  * 跨进程通信：流处理
  * 定期处理累积的大批量数据：批处理


### 关于数据系统的思考
* 新的存储和数据处理工具不断出现，它们针对不同的场景进行优化，因此不在适合生硬地归入传统类别。
  * 缓存Redis可以作为消息队列
  * Kafka消息队列可以向数据库一样持久化消息
* 单个工具不足以满足应用程序的复杂以及严格的要求，总体工作被拆分成一系列能被单个工具高效完成的任务，通过应用代码将它们结合起来。
* 通过API提供多个工具组合后的功能，组合后的工具时一个全新的，专用的数据系统，提供特定的保证。例如缓存在写入时会作废或更新，以便外部客户端获取一致的结果。

#### 可靠性(Reliability)
* 系统在困境(adversity)(硬件、软件故障，人为错误)中仍然可以正常工作(正确完成功能，并达到期望的水准)
* 可靠软件的典型期望
  * 表现出用户所期望的功能
  * 允许用户犯错，允许用户以出乎意料的方式使用软件
  * 在预期的负载和数据量下，性能满足要求
  * 能防止未经授权的访问和滥用
* 故障(fault): 造成错误的原因
* 容错/韧性(fault-tolerant/resilient): 能预料并应对故障的系统特性
* 失效(failure): 故障为系统的部分状态偏离其标准，失效是整个系统停止服务
* 故意触发来提高故障率是有意义的，可以确保容错机制不断运行并接受考验
* 相对于阻止错误，我们应更倾向于容忍错误

#### 硬件故障
* 增加单个硬件的冗余度
#### 软件错误
* 硬件故障一般是随机的、相互独立的，大量硬件组件不太可能同时失效。
* 系统性错误(systematic error)
  * 难以预料、跨节点相关的，可能造成链式失效
  * 接受特定错误输入后导致所有应用服务器实例崩溃的BUG
  * 失控进程会占用一些共享资源
  * 系统依赖的服务变慢或没有正确的响应
  * 级联故障，一个组件中的小故障触发另一个组件中的故障，进而触发更多的故障
* 预防方法
  * 仔细考虑系统中的假设和交互
  * 彻底的测试
  * 进程隔离
  * 允许进程崩溃并重启
  * 测量、监控、并分析生成环境中的系统行为
  * 如果系统能够提供一些保证(例如在一个消息队列中，进入与发出的消息数量相等)，那么系统就可以在运行时不断自检，并在出现差异(discrepancy)时报警。
#### 人为错误
* 以最小化犯错机会的方式设计系统
* 将容易犯错的地方与可能失效的地方解耦，提供一个功能齐全的非生产环境沙箱
* 在各个层次进行彻底的测试
* 允许从人为错误中简单快速地恢复，以最大限度地减少失效情况带来的影响。例如快速回滚配置变更，分批发布新代码，并提供数据重算工具
* 配置详细和明确的监控，比如性能指标和错误率。在其他工程学科中就是遥测(telemetry)
* 良好的管理实践与充分的培训
#### 可靠性有多重要？
* 商务应用中的错误会导致生产力损失（也许数据报告不完整还有法律风险），而电商网站的终端则可能导致收入和声誉的巨大损失。

#### 可扩展性(Scalability)
* 系统现在运行正常，不代表未来也能可靠运行。服务降级(degradation)的一个常见原因是负载增加。

##### 描述负载
* 由合理的办法应对系统的增长(数据量、流量、复杂性)
* 负载参数(load parameters)
  * 每秒Web请求数量
  * 数据库读写比率
  * 同时活跃的用户数量
  * 缓存命中率
  * ...

##### 描述性能
* 增加负载参数并保持系统资源不变时，系统性能收到的影响？
* 增加负载参数并保持性能不变时，需要增加多少系统资源？
* 吞吐量(throughput): 每秒可处理的记录数量，或者在特定规模数据集上运行作业的总时间。通常用在像Hadoop这样的批处理系统上。
* 响应时间(response time): 客户端发送请求到收到响应的时间，通常用于在线系统上。包括网络和排队延时。
  * 响应时间的尾部延时非常重要，因为它直接影响用户体验
    * 响应时间最慢的客户往往是数据最多的客户，也就是最有价值的客户。
    * Amazon观察到：响应时间增加100毫秒，销售量就会减少1%
  * 百分位点通常用于服务基本目标(SLO, service level objectives)和服务级别协议(SLA, service level agreements)
    * 例如服务响应时间的中位数小于200毫秒，且99.9百分位点低于1秒，则认为服务工作正常。
  * 排队延时(queueing delay)通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务，所以只需少量缓慢请求就能阻塞后续请求的处理(头部阻塞 head-of-line blocking)
* 当一个请求需要多个后端请求组合完成时，单个后端慢请求就会拖慢整个终端用户的请求

##### 应对负载的方法
* 纵向扩展(scaling up)/垂直扩展(vertical scaling)
* 横向扩展(scaling out)/水平扩展(horizontal scaling)
* 弹性扩展：检测到负载时自动增加计算资源
* 一个良好适配应用的可扩展架构，是围绕这假设(assumption)建立的
  * 哪些操作是常见的？
  * 哪些操作是罕见的？


#### 可维护性(Maintainability)
* 不同的人员在不同的周期都能在系统上高效地工作
* 可操作性(Operability)：人生苦短，关爱运维
  * 运维的职责
    * 监控系统运行情况，并在服务状态不佳时快速恢复服务
    * 跟踪问题的原因
    * 及时更新软件和平台
    * 了解系统间相互作用，以便在异常造成损失前进行规避
    * 预测未来问题，并在问题出现之前加以解决(如容量规划)
    * 建立部署，配置和管理方面的良好实践，编写相应工具
    * 执行复杂的维护任务，例如将应用程序跨平台迁移
    * 当配置变更时，维持系统的安全性
    * 定义工作流程，使运维操作可预测，并保持生产环境稳定
    * 维持组织对系统的了解
  * 良好的可操作性意外着更轻松的日常工作，进而运维团队能专注于高价值的事情。数据系统可以通过各种方式使日常任务更轻松
    * 通过良好的监控，提供对系统内部状态和运行时行为的可见性(visibility)
    * 为自动化提供良好支持，将系统与标准化工具相集成
    * 避免依赖单台机器(在整个系统继续不间断运行的情况下允许机器停机维护)
    * 提供良好的文档和易于理解的操作模型
    * 提供良好的默认行为，但也允许管理员自由覆盖默认值
    * 有条件时进行自我修复，但也允许管理员手动控制系统状态
    * 行为可预测，最大限度减少意外

* 简单性(Simplicity)：管理复杂度
  * 消除额外的(accidental)复杂度: 由具体实现中出现，而非用户视角的问题本身复杂度。
  * 使用抽象，好的抽象可以将大量实现细节隐藏在一个干净，简单易懂的外观下面。也可以提升代码的复用性，提高效率。

* 可演化性(evolability)：拥抱变化
  * 系统的需求处于常态的变化中
    * 新的事实
    * 意想不到的应用场景
    * 业务优先级变化
    * 用户要求的新功能
    * 新平台取代旧平台
    * 法律法规发生变化
    * 系统增长迫使架构变化
    * ...
  * 敏捷开发模式
  * TDD
  * Refactoring

### 本章小结
* 本章探讨了一些关于数据密集型应用的基本思考方式。这些原则将指导我们阅读本书的其余部分，那里将会深入技术细节。
* 一个应用必须满足各种需求才有用
  * 功能性需求
  * 非功能性需求
    * 通用属性
    * 安全性
    * 合规性
    * 兼容性
    * 可靠性(本章内容)
      * 即使发生软件、硬件或人为故障，系统也能正常工作。容错技术可以对终端用户隐藏某些类型的故障。
    * 可扩展性(本章内容)
      * 即使在负载增加的情况下也保持性能的策略
    * 可维护性(本章内容)
      * 同时也是关于工程师和运维团队的生活质量的。良好的抽象可降低复杂度，并使系统易于修改和适应新的应用场景。


## 第二章 数据模型与查询语言
### 关系模型与文档模型
#### NoSQL的诞生
#### 对象关系不匹配
#### 多对一和多对多的关系
#### 文档数据库是否在重蹈覆辙？
* 网络模型
* 关系模型
* 与文档数据库相比
#### 关系型数据库与文档数据库在今日的对比
* 哪个数据模型更方便写代码？
* 文档模型中的架构灵活性
* 查询的数据局部性
* 文档和关系数据库的融合
### 数据查询语言
#### Web上的声明式查询
#### MapReduce查询
### 图数据模型
#### 属性图
#### Cypher查询语言
#### SQL中的图查询
#### 三元组存储和SPARQL
* 语义网络
* RDF数据模型
#### SPARQL查询语言
#### 基础：Datalog
* 数据模型可能是软件开发中最重要的部分了，因为它们的影响如此深远：不仅仅影响着软件的编写⽅
式，⽽且影响着我们的解题思路。
* 多数应⽤使⽤层层叠加的数据模型构建。对于每层数据模型的关键问题是：它是如何⽤低⼀层数据模型
来表示的？
  * 作为⼀名应⽤开发⼈员，你观察现实世界（⾥⾯有⼈员，组织，货物，⾏为，资⾦流向，传感器
等），并采⽤对象或数据结构，以及操控那些数据结构的API来进⾏建模。那些结构通常是特定于
应⽤程序的。
  * 当要存储那些数据结构时，你可以利⽤通⽤数据模型来表示它们，如JSON或XML⽂档，关系数据
库中的表、或图模型。
  * 数据库软件的⼯程师选定如何以内存、磁盘或⽹络上的字节来表示JSON/XML/关系/图数据。这类
表示形式使数据有可能以各种⽅式来查询，搜索，操纵和处理。
  * 在更低的层次上，硬件⼯程师已经想出了使⽤电流，光脉冲，磁场或者其他东⻄来表示字节的⽅
法。
* ⼀个复杂的应⽤程序可能会有更多的中间层次，⽐如基于API的API，不过基本思想仍然是⼀样的：每个
层都通过提供⼀个明确的数据模型来隐藏更低层次中的复杂性。这些抽象允许不同的⼈群有效地协作。
* 掌握⼀个数据模型需要花费很多精⼒（想想关系数据建模有多少本书）。即便只使⽤⼀个数据模型，不
⽤操⼼其内部⼯作机制，构建软件也是⾮常困难的。然⽽，因为数据模型对上层软件的功能（能做什
么，不能做什么）有着⾄深的影响，所以选择⼀个适合的数据模型是⾮常重要的。

### 关系模型与⽂档模型
* 现在最著名的数据模型可能是SQL。它基于Edgar Codd在1970年提出的关系模型【1】：数据被组织成
关系（SQL中称作表），其中每个关系是元组（SQL中称作⾏)的⽆序集合。

#### NoSQL的诞⽣
* 需要比关系型数据库更好的扩展性，包括非常大的数据集或非常高的写入吞吐量
* 免费和开源
* 关系模型不能很好地支持一些特殊的查询
* 受挫于关系模型的限制性，渴望一种更具多动态性与表现力的数据模型
##### 混合持久化
* SQL和NoSQL混用

#### 对象关系不匹配
* 阻抗不匹配(impedance mismatch): 面向对象的代码存储在SQL表中需要一个笨拙的转换层。
* 对于⼀个像简历这样⾃包含⽂档的数据结构⽽⾔，JSON表示是⾮常合适的：参⻅例2-1。JSON⽐XML更
简单。⾯向⽂档的数据库（如MongoDB，RethinkDB，CouchDB和
Espresso）⽀持这种数据模型。

#### 多对⼀和多对多的关系
* 使用id而不是实际文本的好处
  * 各个简介之间样式和拼写统⼀
  * 避免歧义（例如，如果有⼏个同名的城市）
  * 易于更新——名称只存储在⼀个地⽅，如果需要更改（例如，由于政治事件⽽改变城市名称），很容易进⾏全⾯更新。
  * 本地化⽀持——当⽹站翻译成其他语⾔时，标准化的列表可以被本地化，使得地区和⾏业可以使⽤⽤户的语⾔来显示
  * 更好的搜索——例如，搜索华盛顿州的慈善家就会匹配这份简介，因为地区列表可以编码记录⻄雅图在华盛顿这⼀事实（从"Greater Seattle Area"这个字符串中看不出来）。
* 存储ID还是⽂本字符串，这是个副本（duplication）问题。当使⽤ID时，对⼈类有意义的信息（⽐如
单词：Philanthropy）只存储在⼀处，所有引⽤它的地⽅使⽤ID（ID只在数据库中有意义）。当直接存
储⽂本时，对⼈类有意义的信息会复制在每处使⽤记录中。
* 使⽤ID的好处是，ID对⼈类没有任何意义，因⽽永远不需要改变：ID可以保持不变，即使它标识的信息
发⽣变化。任何对⼈类有意义的东⻄都可能需要在将来某个时候改变——如果这些信息被复制，所有的
冗余副本都需要更新。这会导致写⼊开销，也存在不⼀致的⻛险（⼀些副本被更新了，还有些副本没有
被更新）。去除此类重复是数据库规范化（normalization）的关键思想。

#### ⽂档数据库是否在重蹈覆辙？
#### 关系型数据库与⽂档数据库在今⽇的对⽐
##### 哪个数据模型更⽅便写代码？
* 如果应⽤程序中的数据具有类似⽂档的结构（即，⼀对多关系树，通常⼀次性加载整个树），那么使⽤
⽂档模型可能是⼀个好主意。将类似⽂档的结构分解成多个表的关系技术可能导致繁琐的模式和不必要的复杂的应⽤程序代码。
* 但是，如果你的应⽤程序确实使⽤多对多关系，那么⽂档模型就没有那么吸引⼈了。通过反规范化可以
减少对连接的需求，但是应⽤程序代码需要做额外的⼯作来保持数据的⼀致性。
* 很难说在⼀般情况下哪个数据模型让应⽤程序代码更简单；它取决于数据项之间存在的关系种类。对于
⾼度相联的数据，选⽤⽂档模型是糟糕的，选⽤关系模型是可接受的，⽽选⽤图形模型是最⾃然的。
##### ⽂档模型中的架构灵活性
* ⼤多数⽂档数据库以及关系数据库中的JSON⽀持都不会强制⽂档中的数据采⽤何种模式。关系数据库的
XML⽀持通常带有可选的模式验证。没有模式意味着可以将任意的键和值添加到⽂档中，并且当读取
时，客户端对⽆法保证⽂档可能包含的字段。
* ⽂档数据库有时称为⽆模式（schemaless），但这具有误导性，因为读取数据的代码通常假定某种结
构——即存在隐式模式，但不由数据库强制执⾏。⼀个更精确的术语是读时模式（schema-on-read）（数据的结构是隐含的，只有在数据被读取时才被解释），相应的是写时模式（schema-on-write）（传统的关系数据库⽅法中，模式明确，且数据库确保所有的数据都符合其模式）
* 当由于某种原因（例如，数据是异构的）集合中的项⽬并不都具有相同的结构时,读时模式更具优势
  * 存在许多不同类型的对象，将每种类型的对象放在⾃⼰的表中是不现实的。
  * 数据的结构由外部系统决定。你⽆法控制外部系统且它随时可能变化。
##### 查询的数据局部性
* ⽂档通常以单个连续字符串形式进⾏存储，编码为JSON，XML或其⼆进制变体（如MongoDB的
BSON）。如果应⽤程序经常需要访问整个⽂档（例如，将其渲染⾄⽹⻚），那么存储局部性会带来性
能优势。如果将数据分割到多个表中（如图2-1所示），则需要进⾏多次索引查找才能将其全部检索出
来，这可能需要更多的磁盘查找并花费更多的时间。
* 局部性仅仅适⽤于同时需要⽂档绝⼤部分内容的情况。数据库通常需要加载整个⽂档，即使只访问其中
的⼀⼩部分，这对于⼤型⽂档来说是很浪费的。更新⽂档时，通常需要整个重写。只有不改变⽂档⼤⼩
的修改才可以容易地原地执⾏。因此，通常建议保持相对⼩的⽂档，并避免增加⽂档⼤⼩的写⼊。这些性能限制⼤⼤减少了⽂档数据库的实⽤场景。

##### ⽂档和关系数据库的融合

### 数据查询语⾔
#### Web上的声明式查询
#### MapReduce查询
* MapReduce既不是⼀个声明式的查询语⾔，也不是⼀个完全命令式的查询API，⽽是处于两者之间：查
询的逻辑⽤代码⽚断来表示，这些代码⽚段会被处理框架重复性调⽤。它基于 map （也称
为 collect ）和 reduce （也称为 fold 或 inject ）函数，两个函数存在于许多函数式编程语⾔中。

### 图数据模型
#### 属性图
* 在属性图模型中，每个顶点（vertex）包括：
  * 唯⼀的标识符
  * ⼀组出边（outgoing edges）
  * ⼀组⼊边（ingoing edges）
  * ⼀组属性（键值对）
* 每条边（edge）包括：
  * 唯⼀标识符
  * 边的起点/尾部顶点（tail vertex）
  * 边的终点/头部顶点（head vertex）
  * 描述两个顶点之间关系类型的标签
  * ⼀组属性（键值对）
* 重要特性
  * 任何顶点都可以有⼀条边连接到任何其他顶点。没有模式限制哪种事物可不可以关联。
  * 给定任何顶点，可以⾼效地找到它的⼊边和出边，从⽽遍历图，即沿着⼀系列顶点的路径前后移
动。
  * 通过对不同类型的关系使⽤不同的标签，可以在⼀个图中存储⼏种不同的信息，同时仍然保持⼀个
清晰的数据模型。

#### Cypher查询语⾔
#### SQL中的图查询
#### 三元组存储和SPARQL
* 在三元组存储中，所有信息都以⾮常简单的三部分表示形式存储（主语，谓语，宾语）。例如，三元组
(吉姆, 喜欢 ,⾹蕉)中，吉姆是主语，喜欢是谓语（动词），⾹蕉是对象。
* 三元组的主语相当于图中的⼀个顶点。⽽宾语是下⾯两者之⼀：
  1. 原始数据类型中的值，例如字符串或数字。在这种情况下，三元组的谓语和宾语相当于主语顶点上
  的属性的键和值。例如， (lucy, age, 33) 就像属性 {“age”：33} 的顶点lucy。
  2. 图中的另⼀个顶点。在这种情况下，谓语是图中的⼀条边，主语是其尾部顶点，⽽宾语是其头部顶
  点。例如，在 (lucy, marriedTo, alain) 中主语和宾语 lucy 和 alain 都是顶点，并且谓语
  marriedTo 是连接他们的边的标签。
#### 语义⽹络
#### RDF数据模型
#### SPARQL查询语⾔

### 本章⼩结
数据模型是⼀个巨⼤的课题，在本章中，我们快速浏览了各种不同的模型。我们没有⾜够的空间来详细
介绍每个模型的细节，但是希望这个概述⾜以激起你的兴趣，以更多地了解最适合你的应⽤需求的模
型。
在历史上，数据最开始被表示为⼀棵⼤树（层次数据模型），但是这不利于表示多对多的关系，所以发
明了关系模型来解决这个问题。最近，开发⼈员发现⼀些应⽤程序也不适合采⽤关系模型。新的⾮关系
型“NoSQL”数据存储在两个主要⽅向上存在分歧：
1. ⽂档数据库的应⽤场景是：数据通常是⾃我包含的，⽽且⽂档之间的关系⾮常稀少。
2. 图形数据库⽤于相反的场景：任意事物都可能与任何事物相关联。
这三种模型（⽂档，关系和图形）在今天都被⼴泛使⽤，并且在各⾃的领域都发挥很好。⼀个模型可以
⽤另⼀个模型来模拟 — 例如，图数据可以在关系数据库中表示 — 但结果往往是糟糕的。这就是为什么
我们有着针对不同⽬的的不同系统，⽽不是⼀个单⼀的万能解决⽅案。
⽂档数据库和图数据库有⼀个共同点，那就是它们通常不会为存储的数据强制⼀个模式，这可以使应⽤
程序更容易适应不断变化的需求。但是应⽤程序很可能仍会假定数据具有⼀定的结构；这只是模式是明
确的（写⼊时强制）还是隐含的（读取时处理）的问题。
每个数据模型都具有各⾃的查询语⾔或框架，我们讨论了⼏个例⼦：SQL，MapReduce，MongoDB的
聚合管道，Cypher，SPARQL和Datalog。我们也谈到了CSS和XSL/XPath，它们不是数据库查询语⾔，
⽽包含有趣的相似之处。
虽然我们已经覆盖了很多层⾯，但仍然有许多数据模型没有提到。举⼏个简单的例⼦：
使⽤基因组数据的研究⼈员通常需要执⾏序列相似性搜索，这意味着需要⼀个很⻓的字符串（代表
⼀个DNA分⼦），并在⼀个拥有类似但不完全相同的字符串的⼤型数据库中寻找匹配。这⾥所描
述的数据库都不能处理这种⽤法，这就是为什么研究⼈员编写了像GenBank这样的专⻔的基因组
数据库软件的原因【48】。
粒⼦物理学家数⼗年来⼀直在进⾏⼤数据类型的⼤规模数据分析，像⼤型强⼦对撞机（LHC）这样
的项⽬现在可以⼯作在数百亿兆字节的范围内！在这样的规模下，需要定制解决⽅案来阻住硬件成
本的失控【49】。
全⽂搜索可以说是⼀种经常与数据库⼀起使⽤的数据模型。信息检索是⼀个很⼤的专业课题，我们
不会在本书中详细介绍，但是我们将在第三章和第三章中介绍搜索索引

## 第三章 存储与检索
### 驱动数据库的数据结构
* 为了高效查找数据库中特定键的值，我们需要⼀个数据结构：索引（index）。它保存⼀些额外的元数据作为路标，帮助你找到想要的数据。如果您想在同⼀份数据中以⼏种不同的⽅式进⾏搜索，那么你也许需要不同的索引，建在数据的不同部分上。
* 索引是从主数据衍⽣的附加（additional）结构。许多数据库允许添加与删除索引，这不会影响数据的
内容，它只影响查询的性能。维护额外的结构会产⽣开销，特别是在写⼊时。写⼊性能很难超过简单地
追加写⼊⽂件，因为追加写⼊是最简单的写⼊操作。任何类型的索引通常都会减慢写⼊速度，因为每次
写⼊数据时都需要更新索引。

#### 哈希索引
* 键值存储与在⼤多数编程语⾔中可以找到的字典（dictionary）类型⾮常相似，通常字典都是⽤散列映
射（hash map）（或哈希表（hash table））实现的。
* 但是，哈希表索引也有局限性：
  * 散列表必须能放进内存。如果你有⾮常多的键，原则上可以在磁盘上保留⼀个哈希映射，不幸的是磁盘哈希映
    射很难表现优秀。它需要⼤量的随机访问I/O，当它变满时增⻓是很昂贵的，并且散列冲突需要很
    多的逻辑。
  * 范围查询效率不⾼。例如，您⽆法轻松扫描kitty00000和kitty99999之间的所有键——您必须在散
列映射中单独查找每个键。

#### SSTables和LSM树
* 键值对的序列按键排序, 排序字符串表（Sorted String Table），简称SSTable
  * 合并段是简单⽽⾼效的，即使⽂件⼤于可⽤内存。这种⽅法就像归并排序算法中使⽤的⽅法⼀样, 产⽣新的合并段⽂件，也按键排序。
  * 为了在⽂件中找到⼀个特定的键，你不再需要保存内存中所有键的索引。
##### 构建和维护SSTables
* 写⼊时，将其添加到内存中的平衡树数据结构（例如，红⿊树）。这个内存树有时被称为内存表
（memtable）。
* 当内存表⼤于某个阈值（通常为⼏兆字节）时，将其作为SSTable⽂件写⼊磁盘。这可以⾼效地完
成，因为树已经维护了按键排序的键值对。新的SSTable⽂件成为数据库的最新部分。当SSTable
被写⼊磁盘时，写⼊可以继续到⼀个新的内存表实例。
* 为了提供读取请求，⾸先尝试在内存表中找到关键字，然后在最近的磁盘段中，然后在下⼀个较旧
的段中找到该关键字。
* 有时会在后台运⾏合并和压缩过程以组合段⽂件并丢弃覆盖或删除的值。
##### ⽤SSTables制作LSM树
* 最初这种索引结构是由Patrick O'Neil等⼈描述的。在⽇志结构合并树（或LSM树）的基础上，建
⽴在以前的⼯作上⽇志结构的⽂件系统。基于这种合并和压缩排序⽂件原理的存储引擎通常被称
为LSM存储引擎。
* Lucene是Elasticsearch和Solr使⽤的⼀种全⽂搜索的索引引擎，它使⽤类似的⽅法来存储它的词典
。全⽂索引⽐键值索引复杂得多，但是基于类似的想法：在搜索查询中给出⼀个单词，找到
提及单词的所有⽂档（⽹⻚，产品描述等）。这是通过键值结构实现的，其中键是单词（关键词
（term）），值是包含单词（⽂章列表）的所有⽂档的ID的列表。在Lucene中，从术语到发布列表的
这种映射保存在SSTable类的有序⽂件中，根据需要在后台合并。
##### 性能优化
* 当查找数据库中不存在的键时，LSM树算法可能会很慢：您必须检查内存表，然后将这些段⼀直回到最⽼的（可能必须从磁盘读取每⼀
个），然后才能确定键不存在。为了优化这种访问，存储引擎通常使⽤额外的Bloom过滤器。
（布隆过滤器是⽤于近似集合内容的内存⾼效数据结构，它可以告诉您数据库中是否出现键，从⽽为不
存在的键节省许多不必要的磁盘读取操作。
* 还有不同的策略来确定SSTables如何被压缩和合并的顺序和时间。最常⻅的选择是⼤⼩分层压实。

#### B树
* 使⽤最⼴泛的索引结构在1970年被引⼊，不到10年后变得“⽆处不在”，B树经受了时间的考验。在⼏乎所
有的关系数据库中，它们仍然是标准的索引实现，许多⾮关系数据库也使⽤它们。
* 像SSTables⼀样，B树保持按键排序的键值对，这允许⾼效的键值查找和范围查询。但这就是相似之处
的结尾：B树有着⾮常不同的设计理念。
* 我们前⾯看到的⽇志结构索引将数据库分解为可变⼤⼩的段，通常是⼏兆字节或更⼤的⼤⼩，并且总是
按顺序编写段。相⽐之下，B树将数据库分解成固定⼤⼩的块或⻚⾯，传统上⼤⼩为4KB（有时会更
⼤），并且⼀次只能读取或写⼊⼀个⻚⾯。这种设计更接近于底层硬件，因为磁盘也被安排在固定⼤⼩
的块中。
* ⼀个⻚⾯会被指定为B树的根；在索引中查找⼀个键时，就从这⾥开始。该⻚⾯包含⼏个键和对⼦⻚⾯
的引⽤。每个⼦⻚⾯负责⼀段连续范围的键，引⽤之间的键，指明了引⽤⼦⻚⾯的键范围。

##### 让B树更可靠
* B树的基本底层写操作是⽤新数据覆盖磁盘上的⻚⾯。假定覆盖不改变⻚⾯的位置;即，当⻚⾯被覆盖
时，对该⻚⾯的所有引⽤保持完整。这与⽇志结构索引（如LSM树）形成鲜明对⽐，后者只附加到⽂件
（并最终删除过时的⽂件），但从不修改⽂件。
* 可以考虑将硬盘上的⻚⾯覆盖为实际的硬件操作。在磁性硬盘驱动器上，这意味着将磁头移动到正确
的位置，等待旋转盘上的正确位置出现，然后⽤新的数据覆盖适当的扇区。在固态硬盘上，由于SSD必
须⼀次擦除和重写相当⼤的存储芯⽚块，所以会发⽣更复杂的事情。
* ⼀些操作需要覆盖⼏个不同的⻚⾯。例如，如果因为插⼊导致⻚⾯过度⽽拆分⻚⾯，则需要编写
已拆分的两个⻚⾯，并覆盖其⽗⻚⾯以更新对两个⼦⻚⾯的引⽤。这是⼀个危险的操作，因为如果数据
库在仅有⼀些⻚⾯被写⼊后崩溃，那么最终将导致⼀个损坏的索引（例如，可能有⼀个孤⼉⻚⾯不是任
何⽗项的⼦项）
* 为了使数据库对崩溃具有韧性，B树实现通常会带有⼀个额外的磁盘数据结构：预写式⽇志（WAL,
write-ahead-log）（也称为重做⽇志（redo log））。这是⼀个仅追加的⽂件，每个B树修改都可以
应⽤到树本身的⻚⾯上。当数据库在崩溃后恢复时，这个⽇志被⽤来使B树恢复到⼀致的状态
* 更新⻚⾯的⼀个额外的复杂情况是，如果多个线程要同时访问B树，则需要仔细的并发控制 —— 否则线
程可能会看到树处于不⼀致的状态。这通常通过使⽤锁存器（latches）（轻量级锁）保护树的数据结
构来完成。⽇志结构化的⽅法在这⽅⾯更简单，因为它们在后台进⾏所有的合并，⽽不会⼲扰传⼊的查
询，并且不时地将旧的分段原⼦交换为新的分段。
* ⼀些数据库（如LMDB）使⽤写时复制⽅案，⽽不是覆盖⻚⾯并维护WAL进⾏崩溃恢复。修
改的⻚⾯被写⼊到不同的位置，并且树中的⽗⻚⾯的新版本被创建，指向新的位置。这种⽅法对于
并发控制也很有⽤，我们将在“快照隔离和可重复读”中看到。
* 我们可以通过不存储整个键来节省⻚⾯空间，但可以缩⼩它的⼤⼩。特别是在树内部的⻚⾯上，键
只需要提供⾜够的信息来充当键范围之间的边界。在⻚⾯中包含更多的键允许树具有更⾼的分⽀因
⼦，因此更少的层次
* 通常，⻚⾯可以放置在磁盘上的任何位置；没有什么要求附近的键范围⻚⾯附近的磁盘上。如果查
询需要按照排序顺序扫描⼤部分关键字范围，那么每个⻚⾯的布局可能会⾮常不⽅便，因为每个读
取的⻚⾯都可能需要磁盘查找。因此，许多B树实现尝试布局树，使得叶⼦⻚⾯按顺序出现在磁盘
上。但是，随着树的增⻓，维持这个顺序是很困难的。相⽐之下，由于LSM树在合并过程中⼀次⼜
⼀次地重写存储的⼤部分，所以它们更容易使顺序键在磁盘上彼此靠近。
* 额外的指针已添加到树中。例如，每个叶⼦⻚⾯可以在左边和右边具有对其兄弟⻚⾯的引⽤，这允
许不跳回⽗⻚⾯就能顺序扫描。
* B树的变体如分形树借⽤⼀些⽇志结构的思想来减少磁盘寻道（⽽且它们与分形⽆关）。
##### B树优化
* ⼀些数据库（如LMDB）使⽤写时复制⽅案，⽽不是覆盖⻚⾯并维护WAL进⾏崩溃恢复。修
改的⻚⾯被写⼊到不同的位置，并且树中的⽗⻚⾯的新版本被创建，指向新的位置。这种⽅法对于
并发控制也很有⽤。
* 我们可以通过不存储整个键来节省⻚⾯空间，但可以缩⼩它的⼤⼩。特别是在树内部的⻚⾯上，键
只需要提供⾜够的信息来充当键范围之间的边界。在⻚⾯中包含更多的键允许树具有更⾼的分⽀因
⼦，因此更少的层次
* 通常，⻚⾯可以放置在磁盘上的任何位置；没有什么要求附近的键范围⻚⾯附近的磁盘上。如果查
询需要按照排序顺序扫描⼤部分关键字范围，那么每个⻚⾯的布局可能会⾮常不⽅便，因为每个读
取的⻚⾯都可能需要磁盘查找。因此，许多B树实现尝试布局树，使得叶⼦⻚⾯按顺序出现在磁盘
上。但是，随着树的增⻓，维持这个顺序是很困难的。相⽐之下，由于LSM树在合并过程中⼀次⼜
⼀次地重写存储的⼤部分，所以它们更容易使顺序键在磁盘上彼此靠近。
* 额外的指针已添加到树中。例如，每个叶⼦⻚⾯可以在左边和右边具有对其兄弟⻚⾯的引⽤，这允
许不跳回⽗⻚⾯就能顺序扫描。
* B树的变体如分形树借⽤⼀些⽇志结构的思想来减少磁盘寻道（⽽且它们与分形⽆关）。

#### ⽐较B树和LSM树
* 通常LSM树的写⼊速度更快，⽽B树的读取速度更快。 LSM树上的读取通常⽐较慢，因为它们必须在压缩的
不同阶段检查⼏个不同的数据结构和SSTables。
##### LSM树的优点
* B树索引必须⾄少两次写⼊每⼀段数据：⼀次写⼊预先写⼊⽇志，⼀次写⼊树⻚⾯本身（也许再次分
⻚）。即使在该⻚⾯中只有⼏个字节发⽣了变化，也需要⼀次编写整个⻚⾯的开销。有些存储引擎甚⾄
会覆盖同⼀个⻚⾯两次，以免在电源故障的情况下导致⻚⾯部分更新。
* 由于反复压缩和合并SSTables，⽇志结构索引也会重写数据。这种影响 —— 在数据库的⽣命周期中写
⼊数据库导致对磁盘的多次写⼊ —— 被称为写放⼤（write amplification）。需要特别关注的是固态
硬盘，固态硬盘在磨损之前只能覆写⼀段时间。
* 在写⼊繁重的应⽤程序中，性能瓶颈可能是数据库可以写⼊磁盘的速度。在这种情况下，写放⼤会导致
直接的性能代价：存储引擎写⼊磁盘的次数越多，可⽤磁盘带宽内的每秒写⼊次数越少。
* ⽽且，LSM树通常能够⽐B树⽀持更⾼的写⼊吞吐量，部分原因是它们有时具有较低的写放⼤（尽管这
取决于存储引擎配置和⼯作负载），部分是因为它们顺序地写⼊紧凑的SSTable⽂件⽽不是必须覆盖树
中的⼏个⻚⾯。这种差异在磁性硬盘驱动器上尤其重要，顺序写⼊⽐随机写⼊快得多。
* LSM树可以被压缩得更好，因此经常⽐B树在磁盘上产⽣更⼩的⽂件。 B树存储引擎会由于分割⽽留下
⼀些未使⽤的磁盘空间：当⻚⾯被拆分或某⾏不能放⼊现有⻚⾯时，⻚⾯中的某些空间仍未被使⽤。由
于LSM树不是⾯向⻚⾯的，并且定期重写SSTables以去除碎⽚，所以它们具有较低的存储开销，特别是
当使⽤平坦压缩时
* 在许多固态硬盘上，固件内部使⽤⽇志结构化算法，将随机写⼊转变为顺序写⼊底层存储芯⽚，因此存
储引擎写⼊模式的影响不太明显。但是，较低的写⼊放⼤率和减少的碎⽚对SSD仍然有利：更紧
凑地表示数据可在可⽤的I/O带宽内提供更多的读取和写⼊请求。
##### LSM树的缺点
* ⽇志结构存储的缺点是压缩过程有时会⼲扰正在进⾏的读写操作。尽管存储引擎尝试逐步执⾏压缩⽽不
影响并发访问，但是磁盘资源有限，所以很容易发⽣请求需要等待⽽磁盘完成昂贵的压缩操作。对吞吐
量和平均响应时间的影响通常很⼩，但是在更⾼百分⽐的情况下，对⽇志结构化存
储引擎的查询响应时间有时会相当⻓，⽽B树的⾏为则相对更具可预测性
* 压缩的另⼀个问题出现在⾼写⼊吞吐量：磁盘的有限写⼊带宽需要在初始写⼊（记录和刷新内存表到磁
盘）和在后台运⾏的压缩线程之间共享。写⼊空数据库时，可以使⽤全磁盘带宽进⾏初始写⼊，但数据
库越⼤，压缩所需的磁盘带宽就越多。
* 如果写⼊吞吐量很⾼，并且压缩没有仔细配置，压缩跟不上写⼊速率。在这种情况下，磁盘上未合并段
的数量不断增加，直到磁盘空间⽤完，读取速度也会减慢，因为它们需要检查更多段⽂件。通常情况
下，即使压缩⽆法跟上，基于SSTable的存储引擎也不会限制传⼊写⼊的速率，所以您需要进⾏明确的
监控来检测这种情况
* B树的⼀个优点是每个键只存在于索引中的⼀个位置，⽽⽇志结构化的存储引擎可能在不同的段中有相
同键的多个副本。这个⽅⾯使得B树在想要提供强⼤的事务语义的数据库中很有吸引⼒：在许多关系数
据库中，事务隔离是通过在键范围上使⽤锁来实现的，在B树索引中，这些锁可以直接连接到树。

#### 其他索引结构
* 到⽬前为⽌，我们只讨论了关键值索引，它们就像关系模型中的主键（primary key）索引。主键唯⼀
标识关系表中的⼀⾏，或⽂档数据库中的⼀个⽂档或图形数据库中的⼀个顶点。数据库中的其他记录可
以通过其主键（或ID）引⽤该⾏/⽂档/顶点，并且索引⽤于解析这样的引⽤。
* 有⼆级索引也很常⻅。在关系数据库中，您可以使⽤ CREATE INDEX 命令在同⼀个表上创建多个⼆级
索引，⽽且这些索引通常对于有效地执⾏联接⽽⾔⾄关重要。例如，在第2章中的图2-1中，很可能在
user_id 列上有⼀个⼆级索引，以便您可以在每个表中找到属于同⼀⽤户的所有⾏。
* ⼀个⼆级索引可以很容易地从⼀个键值索引构建。主要的不同是键不是唯⼀的。即可能有许多⾏（⽂
档，顶点）具有相同的键。这可以通过两种⽅式来解决：或者通过使索引中的每个值，成为匹配⾏标识
符的列表（如全⽂索引中的发布列表），或者通过向每个索引添加⾏标识符来使每个关键字唯⼀。⽆论
哪种⽅式，B树和⽇志结构索引都可以⽤作辅助索引。

##### 将值存储在索引中
* 索引中的关键字是查询搜索的内容，但是该值可以是以下两种情况之⼀：它可以是所讨论的实际⾏（⽂
档，顶点），也可以是对存储在别处的⾏的引⽤。在后⼀种情况下，⾏被存储的地⽅被称为堆⽂件
（heap file），并且存储的数据没有特定的顺序（它可以是仅附加的，或者可以跟踪被删除的⾏以便⽤
新数据覆盖它们后来）。堆⽂件⽅法很常⻅，因为它避免了在存在多个⼆级索引时复制数据：每个索引
只引⽤堆⽂件中的⼀个位置，实际的数据保存在⼀个地⽅。 在不更改键的情况下更新值时，堆⽂件⽅法
可以⾮常⾼效：只要新值不⼤于旧值，就可以覆盖该记录。如果新值更⼤，情况会更复杂，因为它可能
需要移到堆中有⾜够空间的新位置。在这种情况下，要么所有的索引都需要更新，以指向记录的新堆位
置，或者在旧堆位置留下⼀个转发指针。
在某些情况下，从索引到堆⽂件的额外跳跃对读取来说性能损失太⼤，因此可能希望将索引⾏直接存储
在索引中。这被称为聚集索引。例如，在MySQL的InnoDB存储引擎中，表的主键总是⼀个聚簇索引，
⼆级索引⽤主键（⽽不是堆⽂件中的位置）。在SQL Server中，可以为每个表指定⼀个聚簇索引
。
* 在聚集索引（clustered index）（在索引中存储所有⾏数据）和⾮聚集索引（nonclustered index）
（仅在索引中存储对数据的引⽤）之间的折衷被称为包含列的索引（index with included columns） 或覆盖索引（covering index），其存储表的⼀部分在索引内【33】。这允许通过单独使⽤索引来回
答⼀些查询（这种情况叫做：索引覆盖（cover）了查询）。
* 与任何类型的数据重复⼀样，聚簇和覆盖索引可以加快读取速度，但是它们需要额外的存储空间，并且
会增加写⼊开销。数据库还需要额外的努⼒来执⾏事务保证，因为应⽤程序不应该因为重复⽽导致不⼀
致。
##### 多列索引
* 最常⻅的多列索引被称为连接索引（concatenated index），它通过将⼀列的值追加到另⼀列后⾯，
简单地将多个字段组合成⼀个键（索引定义中指定了字段的连接顺序）。这就像⼀个⽼式的纸质电话
簿，它提供了⼀个从（姓，名）到电话号码的索引。由于排序顺序，索引可以⽤来查找所有具有特定姓
⽒的⼈，或所有具有特定姓-名组合的⼈。然⽽，如果你想找到所有具有特定名字的⼈，这个索引是没有
⽤的。
* 多维索引（multi-dimensional index）是⼀种查询多个列的更⼀般的⽅法，这对于地理空间数据尤为
重要。例如，餐厅搜索⽹站可能有⼀个数据库，其中包含每个餐厅的经度和纬度。当⽤户在地图上查看
餐馆时，⽹站需要搜索⽤户正在查看的矩形地图区域内的所有餐馆。这需要⼀个⼆维范围查询。
  * SELECT * FROM restaurants WHERE latitude > 51.4946 AND latitude < 51.5079
 AND longitude > -0.1162 AND longitude < -0.1004;
* ⼀个标准的B树或者LSM树索引不能够⾼效地响应这种查询：它可以返回⼀个纬度范围内的所有餐馆
（但经度可能是任意值），或者返回在同⼀个经度范围内的所有餐馆（但纬度可能是北极和南极之间的
任意地⽅），但不能同时满⾜。
*  ⼀种选择是使⽤空间填充曲线将⼆维位置转换为单个数字，然后使⽤常规B树索引。更普遍的
是，使⽤特殊化的空间索引，例如R树。例如，PostGIS使⽤PostgreSQL的通⽤Gist⼯具将地理
空间索引实现为R树。
* 多维索引不仅可以⽤于地理位置。例如，在电⼦商务⽹站上可以使⽤维度（红⾊，
绿⾊，蓝⾊）上的三维索引来搜索特定颜⾊范围内的产品，也可以在天⽓观测数据库中搜索⼆维（⽇
期，温度）的指数，以便有效地搜索2013年的温度在25⾄30°C之间的所有观测资料。使⽤⼀维索引，
你将不得不扫描2013年的所有记录（不管温度如何），然后通过温度进⾏过滤，反之亦然。 ⼆维索引
可以同时通过时间戳和温度来收窄数据集。这个技术被HyperDex使⽤。
##### 全⽂搜索和模糊索引
* 到⽬前为⽌所讨论的所有索引都假定您有确切的数据，并允许您查询键的确切值或具有排序顺序的键的
值范围。他们不允许你做的是搜索类似的键，如拼写错误的单词。这种模糊的查询需要不同的技术。
* 全⽂搜索引擎通常允许搜索⼀个单词以扩展为包括该单词的同义词，忽略单词的语法变体，并且
搜索在相同⽂档中彼此靠近的单词的出现，并且⽀持各种其他功能取决于⽂本的语⾔分析。为了处理⽂
档或查询中的拼写错误，Lucene能够在⼀定的编辑距离内搜索⽂本。
* 正如“在SSTables中创建LSM树”中所提到的，Lucene为其词典使⽤了⼀个类似于SSTable的结构。这个
结构需要⼀个⼩的内存索引，告诉查询在排序⽂件中哪个偏移量需要查找关键字。在LevelDB中，这个
内存中的索引是⼀些键的稀疏集合，但在Lucene中，内存中的索引是键中字符的有限状态⾃动机，类似
于trie。这个⾃动机可以转换成Levenshtein⾃动机，它⽀持在给定的编辑距离内有效地搜索单
词。
##### 在内存中存储⼀切
* 内存数据库重新启动时，需要从磁盘或通过⽹络从副本重新加载其状态（除⾮使⽤特殊的硬件）。尽管
写⼊磁盘，它仍然是⼀个内存数据库，因为磁盘仅⽤作耐久性附加⽇志，读取完全由内存提供。写⼊磁
盘也具有操作优势：磁盘上的⽂件可以很容易地由外部实⽤程序进⾏备份，检查和分析。
* 反直觉的是，内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实。即使是基于磁盘的存储
引擎也可能永远不需要从磁盘读取，因为操作系统缓存最近在内存中使⽤了磁盘块。相反，它们更快的
原因在于省去了将内存数据结构编码为磁盘数据结构的开销。
* 除了性能，内存数据库的另⼀个有趣的领域是提供难以⽤基于磁盘的索引实现的数据模型。例如，
Redis为各种数据结构（如优先级队列和集合）提供了类似数据库的接⼝。因为它将所有数据保存在内
存中，所以它的实现相对简单。

#### 事务处理还是分析？
* 在业务数据处理的早期，对数据库的写⼊通常对应于正在进⾏的商业交易：进⾏销售，向供应商下订
单，⽀付员⼯⼯资等等。随着数据库扩展到那些没有不涉及钱易⼿，术语交易仍然卡住，指的是形成⼀
个逻辑单元的⼀组读写。 事务不⼀定具有ACID（原⼦性，⼀致性，隔离性和持久性）属性。事务处理
只是意味着允许客户端进⾏低延迟读取和写⼊ —— ⽽不是批量处理作业，⽽这些作业只能定期运⾏
（例如每天⼀次）。我们在第7章中讨论ACID属性，在第10章中讨论批处理。
* 即使数据库开始被⽤于许多不同类型的博客⽂章，游戏中的动作，地址簿中的联系⼈等等，基本访问模
式仍然类似于处理业务事务。应⽤程序通常使⽤索引通过某个键查找少量记录。根据⽤户的输⼊插⼊或
更新记录。由于这些应⽤程序是交互式的，因此访问模式被称为在线事务处理（OLTP, OnLine
Transaction Processing）。
* 但是，数据库也开始越来越多地⽤于数据分析，这些数据分析具有⾮常不同的访问模式。通常，分析查
询需要扫描⼤量记录，每个记录只读取⼏列，并计算汇总统计信息（如计数，总和或平均值），⽽不是
将原始数据返回给⽤户。例如，如果您的数据是⼀个销售交易表，那么分析查询可能是
  * ⼀⽉份我们每个商店的总收⼊是多少？
  * 我们在最近的推⼴活动中销售多少⾹蕉？
  * 哪种品牌的婴⼉⻝品最常与X品牌的尿布⼀起购买？
* 这些查询通常由业务分析师编写，并提供给帮助公司管理层做出更好决策（商业智能）的报告。为了区
分这种使⽤数据库的事务处理模式，它被称为在线分析处理（OLAP, OnLine Analytice
Processing）。
* OLTP vs OLAP
  * 主要读取模式：查询少量，按键读取 vs 在大批量记录上聚合
  * 主要写入模式：随机访问，写入要求低延时 vs 批量导入，事件流
  * 主要用户：终端用户，通过Web应用 vs 内部数据分析师，决策支持
  * 处理的数据： 数据的最新状态 vs 随时间推移的历史事件
  * 数据集尺寸：GB ~ TB vs TB ~ PB

#### 数据仓库
* ⼀个企业可能有⼏⼗个不同的交易处理系统：系统为⾯向客户的⽹站提供动⼒，控制实体商店的销售点
（checkout）系统，跟踪仓库中的库存，规划⻋辆路线，管理供应商，管理员⼯等。这些系统中的每
⼀个都是复杂的，需要⼀个⼈员去维护，所以系统最终都是⾃动运⾏的。
* 这些OLTP系统通常具有⾼度的可⽤性，并以低延迟处理事务，因为这些系统往往对业务运作⾄关重
要。因此数据库管理员密切关注他们的OLTP数据库他们通常不愿意让业务分析⼈员在OLTP数据库上运
⾏临时分析查询，因为这些查询通常很昂贵，扫描⼤部分数据集，这会损害同时执⾏的事务的性能。
* 相⽐之下，数据仓库是⼀个独⽴的数据库，分析⼈员可以查询他们⼼中的内容，⽽不影响OLTP操作
。数据仓库包含公司所有各种OLTP系统中的只读数据副本。从OLTP数据库中提取数据（使⽤定
期的数据转储或连续的更新流），转换成适合分析的模式，清理并加载到数据仓库中。将数据存⼊仓库
的过程称为“抽取-转换-加载（ETL）”，如图3-8所示。
* ⼏乎所有的⼤型企业都有数据仓库，但在⼩型企业中⼏乎闻所未闻。这可能是因为⼤多数⼩公司没有这
么多不同的OLTP系统，⼤多数⼩公司只有少量的数据 —— 可以在传统的SQL数据库中查询，甚⾄可以
在电⼦表格中分析。在⼀家⼤公司⾥，要做⼀些在⼀家⼩公司很简单的事情，需要很多繁重的⼯作。
* 使⽤单独的数据仓库，⽽不是直接查询OLTP系统进⾏分析的⼀⼤优势是数据仓库可针对分析访问模式
进⾏优化。事实证明，本章前半部分讨论的索引算法对于OLTP来说⼯作得很好，但对于回答分析查询
并不是很好。在本章的其余部分中，我们将看看为分析⽽优化的存储引擎。

##### OLTP数据库和数据仓库之间的分歧
* 数据仓库的数据模型通常是关系型的，因为SQL通常很适合分析查询。有许多图形数据分析⼯具可以⽣
成SQL查询，可视化结果，并允许分析⼈员探索数据（通过下钻，切⽚和切块等操作）。
* 表⾯上，⼀个数据仓库和⼀个关系OLTP数据库看起来很相似，因为它们都有⼀个SQL查询接⼝。然⽽，
系统的内部看起来可能完全不同，因为它们针对⾮常不同的查询模式进⾏了优化。现在许多数据库供应
商都将重点放在⽀持事务处理或分析⼯作负载上，⽽不是两者都⽀持。
* ⼀些数据库（例如Microsoft SQL Server和SAP HANA）⽀持在同⼀产品中进⾏事务处理和数据仓库。
但是，它们正在⽇益成为两个独⽴的存储和查询引擎，这些引擎正好可以通过⼀个通⽤的SQL接⼝访问。
* Teradata，Vertica，SAP HANA和ParAccel等数据仓库供应商通常使⽤昂贵的商业许可证销售他们的系
统。 Amazon RedShift是ParAccel的托管版本。最近，⼤量的开源SQL-on-Hadoop项⽬已经出现，它
们还很年轻，但是正在与商业数据仓库系统竞争。这些包括Apache Hive，Spark SQL，Cloudera
Impala，Facebook Presto，Apache Tajo和Apache Drill 【52,53】。其中⼀些是基于⾕歌的Dremel
的想法。

#### 星型和雪花型：分析的模式
* 根据应⽤程序的需要，在事务处理领域中使⽤了⼤量不同的数据模型。另⼀⽅
⾯，在分析中，数据模型的多样性则少得多。许多数据仓库都以相当公式化的⽅式使⽤，被称为星型模
式（也称为维度建模）。
* 通常情况下，事实被视为单独的事件，因为这样可以在以后分析中获得最⼤的灵活性。但是，这意味着
事实表可以变得⾮常⼤。
* 事实表中的⼀些列是属性，例如产品销售的价格和从供应商那⾥购买的成本（允许计算利润余额）。事
实表中的其他列是对其他表（称为维表）的外键引⽤。由于事实表中的每⼀⾏都表示⼀个事件，因此这
些维度代表事件的发⽣地点，时间，⽅式和原因。
* 例如⼀个维度是已售出的产品。 dim_product 表中的每⼀⾏代表⼀种待售产品，
包括库存单位（SKU），说明，品牌名称，类别，脂肪含量，包装尺⼨等。 fact_sales 表中的每⼀⾏
都使⽤外部表明在特定交易中销售了哪些产品。 （为了简单起⻅，如果客户⼀次购买⼏种不同的产品，
则它们在事实表中被表示为单独的⾏）。
* 即使⽇期和时间通常使⽤维度表来表示，因为这允许对⽇期（诸如公共假期）的附加信息进⾏编码，从
⽽允许查询区分假期和⾮假期的销售。
* “星型模式”这个名字来源于这样⼀个事实，即当表关系可视化时，事实表在中间，由维表包围；与这些
表的连接就像星星的光芒。
* 这个模板的变体被称为雪花模式，其中尺⼨被进⼀步分解为⼦尺⼨。例如，品牌和产品类别可能有单独
的表格，并且 dim_product 表格中的每⼀⾏都可以将品牌和类别作为外键引⽤，⽽不是将它们作为字
符串存储在 dim_product 表格中。雪花模式⽐星形模式更规范化，但是星形模式通常是⾸选，因为分
析师使⽤它更简单。
* 在典型的数据仓库中，表格通常⾮常宽泛：事实表格通常有100列以上，有时甚⾄有数百列。维
度表也可以是⾮常宽的，因为它们包括可能与分析相关的所有元数据——例如， dim_store 表可以包
括在每个商店提供哪些服务的细节，它是否具有店内⾯包房，⽅形镜头，商店第⼀次开幕的⽇期，最后
⼀次改造的时间，离最近的⾼速公路的距离等等。
* 这个模板的变体被称为雪花模式，其中尺⼨被进⼀步分解为⼦尺⼨。例如，品牌和产品类别可能有单独
的表格，并且 dim_product 表格中的每⼀⾏都可以将品牌和类别作为外键引⽤，⽽不是将它们作为字
符串存储在 dim_product 表格中。雪花模式⽐星形模式更规范化，但是星形模式通常是⾸选，因为分
析师使⽤它更简单。
* 在典型的数据仓库中，表格通常⾮常宽泛：事实表格通常有100列以上，有时甚⾄有数百列【51】。维
度表也可以是⾮常宽的，因为它们包括可能与分析相关的所有元数据——例如， dim_store 表可以包
括在每个商店提供哪些服务的细节，它是否具有店内⾯包房，⽅形镜头，商店第⼀次开幕的⽇期，最后
⼀次改造的时间，离最近的⾼速公路的距离等等。

#### 列存储
* 如果事实表中有万亿⾏和数PB的数据，那么⾼效地存储和查询它们就成为⼀个具有挑战性的问题。维度
表通常要⼩得多（数百万⾏），所以在本节中我们将主要关注事实的存储。
* 尽管事实表通常超过100列，但典型的数据仓库查询⼀次只能访问4个或5个查询（ “ SELECT * ” 查询
很少⽤于分析）。以例3-1中的查询为例：它访问了⼤量的⾏（在2013⽇历年中每次都有⼈购买
⽔果或糖果），但只需访问 fact_sales 表的三列： date_key, product_sk, quantity 。查询忽略
所有其他列。
* 在⼤多数OLTP数据库中，存储都是以⾯向⾏的⽅式进⾏布局的：表格的⼀⾏中的所有值都相邻存储。
⽂档数据库是相似的：整个⽂档通常存储为⼀个连续的字节序列。
* 为了处理像例3-1这样的查询，您可能在 fact_sales.date_key ， fact_sales.product_sk 上有索
引，它们告诉存储引擎在哪⾥查找特定⽇期或特定产品的所有销售情况。但是，⾯向⾏的存储引擎仍然
需要将所有这些⾏（每个包含超过100个属性）从磁盘加载到内存中，解析它们，并过滤掉那些不符合
要求的条件。这可能需要很⻓时间。
* ⾯向列的存储背后的想法很简单：不要将所有来⾃⼀⾏的值存储在⼀起，⽽是将来⾃每⼀列的所有值存
储在⼀起。如果每个列存储在⼀个单独的⽂件中，查询只需要读取和解析查询中使⽤的那些列，这可以
节省⼤量的⼯作。

##### 列压缩
* 除了仅从磁盘加载查询所需的列以外，我们还可以通过压缩数据来进⼀步降低对磁盘吞吐量的需求。幸
运的是，⾯向列的存储通常很适合压缩。

##### 列存储中的排序顺序
* 在列存储中，存储⾏的顺序并不⼀定很重要。按插⼊顺序存储它们是最简单的，因为插⼊⼀个新⾏就意
味着附加到每个列⽂件。但是，我们可以选择强制执⾏⼀个命令，就像我们之前对SSTables所做的那
样，并将其⽤作索引机制。
* 在⼀个⾯向列的存储中有多个排序顺序有点类似于在⼀个⾯向⾏的存储中有多个⼆级索引。但最⼤的区
别在于⾯向⾏的存储将每⼀⾏保存在⼀个地⽅（在堆⽂件或聚簇索引中），⼆级索引只包含指向匹配⾏
的指针。在列存储中，通常在其他地⽅没有任何指向数据的指针，只有包含值的列。
#### 写⼊列存储
* 这些优化在数据仓库中是有意义的，因为⼤多数负载由分析⼈员运⾏的⼤型只读查询组成。⾯向列的存
储，压缩和排序都有助于更快地读取这些查询。然⽽，他们有写更加困难的缺点。
* 使⽤B树的更新就地⽅法对于压缩的列是不可能的。如果你想在排序表的中间插⼊⼀⾏，你很可能不得
不重写所有的列⽂件。由于⾏由列中的位置标识，因此插⼊必须始终更新所有列。
* 幸运的是，本章前⾯已经看到了⼀个很好的解决⽅案：LSM树。所有的写操作⾸先进⼊⼀个内存中的存
储，在这⾥它们被添加到⼀个已排序的结构中，并准备写⼊磁盘。内存中的存储是⾯向⾏还是列的，这
并不重要。当已经积累了⾜够的写⼊数据时，它们将与磁盘上的列⽂件合并，并批量写⼊新⽂件。这基
本上是Vertica所做的。
* 查询需要检查磁盘上的列数据和最近在内存中的写⼊，并将两者结合起来。但是，查询优化器隐藏了⽤
户的这个区别。从分析师的⻆度来看，通过插⼊，更新或删除操作进⾏修改的数据会⽴即反映在后续查
询中。
##### 聚合：数据⽴⽅体和物化视图
* 并不是每个数据仓库都必定是⼀个列存储：传统的⾯向⾏的数据库和其他⼀些架构也被使⽤。然⽽，对
于专⻔的分析查询，列式存储可以显着加快，所以它正在迅速普及。
* 数据仓库的另⼀个值得⼀提的是物化汇总。如前所述，数据仓库查询通常涉及⼀个聚合函数，如SQL中 的COUNT，SUM，AVG，MIN或MAX。如果相同的聚合被许多不同的查询使⽤，那么每次都可以通过
原始数据来处理。为什么不缓存⼀些查询使⽤最频繁的计数或总和？
* 创建这种缓存的⼀种⽅式是物化视图。在关系数据模型中，它通常被定义为⼀个标准（虚拟）视图：⼀
个类似于表的对象，其内容是⼀些查询的结果。不同的是，物化视图是查询结果的实际副本，写⼊磁
盘，⽽虚拟视图只是写⼊查询的捷径。从虚拟视图读取时，SQL引擎会将其展开到视图的底层查询中，
然后处理展开的查询。
* 当底层数据发⽣变化时，物化视图需要更新，因为它是数据的⾮规范化副本。数据库可以⾃动完成，但
是这样的更新使得写⼊成本更⾼，这就是在OLTP数据库中不经常使⽤物化视图的原因。在读取繁重的
数据仓库中，它们可能更有意义（不管它们是否实际上改善了读取性能取决于个别情况。
* 物化视图的常⻅特例称为数据⽴⽅体或OLAP⽴⽅。它是按不同维度分组的聚合⽹格。图3-12显
示了⼀个例⼦。

#### 本章⼩结
* 在本章中，我们试图深⼊了解数据库如何处理存储和检索。将数据存储在数据库中会发⽣什么，以及稍
后再次查询数据时数据库会做什么？
* 在⾼层次上，我们看到存储引擎分为两⼤类：优化事务处理（OLTP）和优化分析（OLAP）的类别。这
些⽤例的访问模式之间有很⼤的区别：
  * OLTP系统通常⾯向⽤户，这意味着他们可能会看到⼤量的请求。为了处理负载，应⽤程序通常只
触及每个查询中的少量记录。应⽤程序使⽤某种键来请求记录，存储引擎使⽤索引来查找所请求的
键的数据。磁盘寻道时间往往是这⾥的瓶颈。
  * 数据仓库和类似的分析系统不太知名，因为它们主要由业务分析⼈员使⽤，⽽不是由最终⽤户使
⽤。它们处理⽐OLTP系统少得多的查询量，但是每个查询通常要求很⾼，需要在短时间内扫描数
百万条记录。磁盘带宽（不是查找时间）往往是瓶颈，列式存储是这种⼯作负载越来越流⾏的解决
⽅案。

* OLTP两⼤主流学派的存储引擎
  * ⽇志结构学派: 只允许附加到⽂件和删除过时的⽂件，但不会更新已经写⼊的⽂件。 Bitcask，SSTables，LSM树，LevelDB，Cassandra，HBase，Lucene等都属于这个组。
  * 就地更新学派: 将磁盘视为⼀组可以覆盖的固定⼤⼩的⻚⾯。 B树是这种哲学的最⼤的例⼦，被⽤在所有主要的关系数据库中，还有许多⾮关系数据库。
* ⽇志结构的存储引擎是相对较新的发展。他们的主要想法是，他们系统地将随机访问写⼊顺序写⼊磁
盘，由于硬盘驱动器和固态硬盘的性能特点，可以实现更⾼的写⼊吞吐量。在完成OLTP⽅⾯，我们通
过⼀些更复杂的索引结构和为保留所有数据⽽优化的数据库做了⼀个简短的介绍。
* 典型数据仓库的⾼级架构。这⼀背景说明了为什么分析⼯作负
载与OLTP差别很⼤：当您的查询需要在⼤量⾏中顺序扫描时，索引的相关性就会降低很多。相反，⾮
常紧凑地编码数据变得⾮常重要，以最⼤限度地减少查询需要从磁盘读取的数据量。我们讨论了列式存
储如何帮助实现这⼀⽬标。
* 作为⼀名应⽤程序开发⼈员，如果您掌握了有关存储引擎内部的知识，那么您就能更好地了解哪种⼯具
最适合您的特定应⽤程序。如果您需要调整数据库的调整参数，这种理解可以让您设想⼀个更⾼或更低
的值可能会产⽣什么效果。

##### ⼏个不同的排序顺序

#### 写⼊列存储



## 第四章 编码与演化
* 大多数情况下，更改app功能时，其存储的数据也需要更改。但面临很多挑战
  * 服务端app需要滚动升级
  * 客户端app需要客户配合升级，但是往往客户不会第一时间更新
* 需要保持向前后兼容

### 数据编码格式
* 程序中常见的两种数据表示形式
  * 内存中，数据保存在对象、结构体、列表、数组、哈希表和树等数据结构中。它们针对CPU的高效访问和操作进行了优化。(通常使用指针)
  * 将数据写入文件或通过网络发送时，需要序列化成字节序列，例如JSON。由于指针对其他进程无意义，所以字节序列和内存中结构是不一样的。

#### 语言的特定格式
* Java Serializable, Python pickle等
* 问题
  * 编码(序列化)跨语言访问非常困难
  * 解码(反序列化)过程有安全隐患
  * 向前后兼容容易被忽略
  * 性能问题

#### JSON、XML与二进制变体
* JSON，XML和CSV都是文本格式，具有不错的可读性，但是也有一定问题
  * 数字编码问题，XML和CSV中，数字和数字字符串无法区分。JSON可以区分，但不能区分小数和整数。并且它们处理大数字时也有问题(2^53以上的数在IEEE 754双精度浮点数中不能精确表示)。
  * JSON和XML不支持二进制字符串。它们有模式支持，但是学习起来复杂。
  * CSV没有模式支持。

#### 二进制编码
* 当数据量达到TB级别时，数据格式的选择就会产生很大影响。
* JSON比XML简约，但比起二进制格式，还是占用了很大空间。
  * BSON, BJSON, MessagePack, UBJSON, BISON, Smile等

#### Thrift, Protocol Buffers, Avro
* 相同原理的两种二进制代码库

### 数据流模式
* 最常见的进程间数据流动方式
  * 数据库
  * 服务调用
  * 异步消息
#### 基于数据库的数据流
* 向前后兼容性是必要的
###### 不同时间写入不同值
* 数据库内的数据可能是多年前的，即使应用版本经过了很多次更新。数据比代码更长久
* 将数据重写为新模式是可行的，但是代价很大。
* 大多数关系型数据库允许进行简单的模式更改，例如添加具有默认值空的新列， 而不重写现有数据。

##### 归档存储
* 经常为数据库创建快照的场景，例如备份或加载到数据仓库。这种情况下通常将数据转存为最新的模式编码。

### 基于服务的数据流：REST和RPC
* 在某些方面，服务类似于数据库，它们通常允许客户端提交和查询数据。
* SOA和Microservice的一个关键设计目标是，通过使服务可独立部署演化，让应用程序更易更改和维护。

#### 网络服务
* 客户端到服务端
* 服务端到服务端
* 公共API
* REST
  * 基于HTTP原则的设计理念，强调简单的数据格式，使用URL来标识资源，使用HTTP功能进行缓存控制、身份验证和内容类型协商
* SOAP
  * 基于XML，目的是独立于HTTP，避免使用大多数HTTP功能。

#### RPC的问题
* 网络请求不可预测，并且网络问题很常见
* 由于超时，无法知道究竟发生了什么
* 如果重试失败的网络请求，可能会发生请求实际上已经完成，只是响应丢失的情况。会导致重试操作被执行多次，造成重复数据。
* 性能问题
* 需要序列化和反序列化
* 不同语言之间的通信会有问题

#### RPC发展方向

#### RPC的数据编码和演化

### 基于消息传递的数据流
* 通过消息中间件发送异步消息。
* 优点
  * 如果接收方不可用或过载，消息代理可以充当缓冲区，从而提高系统可用性
  * 可以自动将消息重新发送到崩溃的进程，从而防止消息丢失
  * 避免了发送方需要知道对方的地址
  * 支持广播模式
  * 逻辑上将发送方和接收方解耦

#### 消息代理
#### 分布式Actor框架
* 用于单个进程中并非的编程模型。每个Actor代表一个客户端或实体，它可能具有某些本地状态，并且它通过发送和接收异步消息与其他Actor通信。
* Akka: 使用Java内置的序列化，不提供向前后兼容的能力。但是可以使用Protocol Buffer来获得滚动升级的能力
* Orleans
* Erlang OTP

### 小结


# 第二部分 分布式数据
* 分布在多台机器上的数据，对于可扩展性是必须的，同时带来了许多独特挑战
  * 可扩展性
  * 容错/高可用性
  * 降低地理延时
## 扩展至更高的负荷
* 垂直扩展：使用更强大的硬件
  * 成本增长的速度快于线性增长，双倍的性能需要不止双倍的成本
  * 提供有限的容错能力，但是受到地理位置限制
  * 共享磁盘架构：多台独立CPU和内存的机器共享一个磁盘。用于一些数据仓库，但是竞争和锁定的开销限制了共享磁盘的可扩展性
### 无共享架构(水平扩展)
* 多节点，每个节点只使用自己独立的硬件，节点间的所有协调通过软件和网络实现。
* 无需特殊的硬件，使用云平台可以轻松实现

## 复制 vs 分区
#### 复制（Replication）
* 在多个节点上保持数据的相同副本，提供了冗余。可以提升可用性和性能。
#### 分区(partitioning/sharding)
* 将一个大型数据拆分成较小的子集，从而不同的分区可以指派给不同的节点。
* 复制和分区是不同的机制，但它们经常同时使用。

## 第五章 复制
### 领导者与追随者
* 数据库的写操作需要传播到所有副本上，否则副本就会包含不一样的数据。
  * 基于领导者的复制
    * 写入请求都发给领导者，领导者将新数据写入本地存储
    * 领导者写入本地存储时，将数据变更发送给所有的追随者(replication log/change stream)。每个跟随着从领导者拉取日志，并更新相应的本地数据库，按照领导者处理的相同顺序写入
    * 客户端读操作可以向领导者或追随者查询。
### 同步复制与异步复制
* 同步：从库保证与主库一致的最新数据副本。如果主库突然失效，可以确保这些数据仍然能在从库上找到。但是如果同步从库的过程没有相应，主库就无法处理写入操作。因此，将所有从库都设为同步时不实际的，因为任何一个节点故障都会导致整个系统停滞。实际上，如果数据库启动同步，通常意味着只有一个跟随者是同步的，其他则是异步的。这种配置也被称为半同步。
* 通常情况下，基于领导者的复制都配置为完全异步，这样如果主库失效且不可恢复，任何尚未复制给从库的写入都会丢失。这可能会导致即使已经向客户端确认成功，写入也不能保证持久。优点是即使所有的从库都落后了，主库也可以继续处理写入。

### 设置新从库
* 添加一个全新的从库的步骤(通常不需要停机)
  * 在某个时刻获取主库的一致性快照(如果可能)，而不必锁定整个数据库。
  * 将快照复制到新的从库节点。
  * 从库连接到主库，并拉取快照之后所有的数据变更。
  * 当从库处理完快照之后挤压的数据变更，它就可以继续处理主库产生的数据变化了。

### 处理节点宕机
#### 从库失效：追赶恢复
* 从库从日志中可以知道发送故障前最后一个事务，然后连接到主库，同步断开之后的所有数据变更。
#### 主库失效：故障切换(failover)
* 一个从库需要被提升为新的主库，并且重新配置客户端，以将它们的写操作发送给新的主库，其他从库需要开始拉取来自新主库的数据变更。
* 自动故障切换的步骤
  * 确定主库失效，但并没有万无一失的方法来检查，通常只是使用简单的超时机制。
  * 选择一个新的主库。可以通过选举或仲裁节点来指定。
  * 重新配置系统以启动新的主库，同时老的主库恢复后称为从库。

### 复制日志的实现
#### 基于语句的复制
* 主库记录下所有的写入请求(例如SQL语句)，并将该语句日志发送给从库。
  * 非确定性函数可能会产生不同的值，如NOW()、RAND()方法。
  * 自增列或依赖本地现有数据的表需要在副本上用完全相同的顺序执行它们。当有多个并发事务时，这可能成为一个限制。
  * 有副作用(触发器，存储过程，用户定义的函数)的语句可能在每个副本上产生不同的副作用，触发副作用时确定的。

#### 传输预写式日志(Write Ahead Log, WAL)
* ⽇志都是包含所有数据库写⼊的仅追加字节序列。可以使⽤完全相同的⽇志在另⼀
个节点上构建副本：除了将⽇志写⼊磁盘之外，主库还可以通过⽹络将其发送给其从库。
当从库应⽤这个⽇志时，它会建⽴和主库⼀模⼀样数据结构的副本。

#### 逻辑⽇志复制（基于⾏）
* 复制和存储引擎使⽤不同的⽇志格式，这样可以使复制⽇志从存储引擎内部分离出来。
这种复制⽇志被称为逻辑⽇志，以将其与存储引擎的（物理）数据表示区分开来。
  * 对于插⼊的⾏，⽇志包含所有列的新值
  * 对于删除的⾏，⽇志包含⾜够的信息来唯⼀标识已删除的⾏。通常是主键，但是如果表上没有主
键，则需要记录所有列的旧值。
  * 对于更新的⾏，⽇志包含⾜够的信息来唯⼀标识更新的⾏，以及所有列的新值（或⾄少所有已更改
的列的新值）。

#### 基于触发器的复制
* 触发器允许您注册在数据库系统中发⽣数据更改（写⼊事务）时⾃动执⾏的⾃定义应⽤程序代码。触发
器有机会将更改记录到⼀个单ᇿ的表中，使⽤外部程序读取这个表，再加上任何业务逻辑处理，会后将
数据变更复制到另⼀个系统去。例如，Databus for Oracle 【20】和Bucardo for Postgres 【21】就是
这样⼯作的。

### 复制延迟问题
* 当应⽤程序从异步从库读取时，如果从库落后，它可能会看到过时的信息。这会导致数据库
中出现明显的不⼀致：同时对主库和从库执⾏相同的查询，可能得到不同的结果，因为并⾮所有的写⼊
都反映在从库中。这种不⼀致只是⼀个暂时的状态——如果停⽌写⼊数据库并等待⼀段时间，从库最终
会赶上并与主库保持⼀致。出于这个原因，这种效应被称为最终⼀致性（eventually
consistency）

#### 读⼰之写
* 如果用户重新加载⻚⾯，他们总会看到
他们⾃⼰提交的任何更新。它不会对其他⽤户的写⼊做出承诺：其他⽤户的更新可能稍等才会看到。它
保证⽤户⾃⼰的输⼊已被正确保存。
  * 从主库读取⽤户⾃⼰的档案，在从库读取其他⽤户的档案。
  * 如果应⽤中的⼤部分内容都可能被⽤户编辑，那这种⽅法就没⽤了，因为⼤部分内容都必须从主库
读取（扩容读就没效果了）。在这种情况下可以使⽤其他标准来决定是否从主库读取。例如可以跟
踪上次更新的时间，在上次更新后的⼀分钟内，从主库读。还可以监控从库的复制延迟，防⽌任向
任何滞后超过⼀分钟到底从库发出查询。
  * 客户端可以记住最近⼀次写⼊的时间戳，系统需要确保从库为该⽤户提供任何查询时，该时间戳前
的变更都已经传播到了本从库中。如果当前从库不够新，则可以从另⼀个从库读，或者等待从库追
赶上来。
  * 如果您的副本分布在多个数据中⼼（出于可⽤性⽬的与⽤户尽量在地理上接近），则会增加复杂
性。任何需要由领导者提供服务的请求都必须路由到包含主库的数据中⼼

#### 单调读
* 实现单调读取的⼀种⽅式是确保每个⽤户总是从同⼀个副本进⾏读取（不同的⽤户可以从不同的副本读
取）。例如，可以基于⽤户ID的散列来选择副本，⽽不是随机选择副本。但是，如果该副本失败，⽤户
的查询将需要重新路由到另⼀个副本。

#### ⼀致前缀读
* 如果⼀系列写⼊按某个顺序发⽣，那么任何⼈读取这些写⼊时，也会看⻅它们以同样的顺序出现。
* 这是分区（partitioned）（分⽚（sharded））数据库中的⼀个特殊问题，将在第6章中讨论。如果数
据库总是以相同的顺序应⽤写⼊，则读取总是会看到⼀致的前缀，所以这种异常不会发⽣。但是在许多
分布式数据库中，不同的分区ᇿ⽴运⾏，因此不存在全局写⼊顺序：当⽤户从数据库中读取数据时，可
能会看到数据库的某些部分处于较旧的状态，⽽某些处于较新的状态。
* ⼀种解决⽅案是，确保任何因果相关的写⼊都写⼊相同的分区。对于某些⽆法⾼效完成这种操作的应
⽤，还有⼀些显式跟踪因果依赖关系的算法，本书将在“关系与并发”⼀节中返回这个主题。

#### 复制延迟的解决⽅案
* 在使⽤最终⼀致的系统时，如果复制延迟增加到⼏分钟甚⾄⼏⼩时，则应该考虑应⽤程序的⾏为。如果
答案是“没问题”，那很好。但如果结果对于⽤户来说是不好体验，那么设计系统来提供更强的保证是很
重要的，例如写后读。明明是异步复制却假设复制是同步的，这是很多麻烦的根源

### 多主复制
#### 多主复制的应⽤场景
##### 运维多个数据中⼼
* 多领导者配置中可以在每个数据中⼼都有主库。在每个数据中⼼内使⽤
常规的主从复制；在数据中⼼之间，每个数据中⼼的主库都会将其更改复制到其他数据中⼼的主库中。
  * 更高的性能
  * 容忍数据中心停机
  * 容忍网络问题
##### 需要离线操作的客户端
* 每个设备都有⼀个充当领导者的本地数据库（它接受写请求），并且在所有设备上的⽇
历副本之间同步时，存在异步的多主复制过程。复制延迟可能是⼏⼩时甚⾄⼏天，具体取决于何时可以
访问互联⽹。

##### 协同编辑
* 当⼀个⽤户编辑⽂档时，所做
的更改将⽴即应⽤到其本地副本（Web浏览器或客户端应⽤程序中的⽂档状态），并异步复制到服务器
和编辑同⼀⽂档的任何其他⽤户。
* 如果要保证不会发⽣编辑冲突，则应⽤程序必须先取得⽂档的锁定，然后⽤户才能对其进⾏编辑。如果
另⼀个⽤户想要编辑同⼀个⽂档，他们⾸先必须等到第⼀个⽤户提交修改并释放锁定。这种协作模式相
当于在领导者上进⾏交易的单领导者复制。
* 但是，为了加速协作，您可能希望将更改的单位设置得⾮常⼩（例如，⼀个按键），并避免锁定。这种
⽅法允许多个⽤户同时进⾏编辑，但同时也带来了多领导者复制的所有挑战，包括需要解决冲突

#### 处理写⼊冲突

##### 同步与异步冲突检测
##### 避免冲突
##### 收敛⾄⼀致的状态
##### ⾃定义冲突解决逻辑
* 写时执⾏
* 读时执⾏

#### 多主复制拓扑
* Circular Topology
* Star Topology
* All-to-all Topology
  * 容错性更好，允许消息沿着不同路径传播，避免单点故障

### ⽆主复制
* 放弃主库的概念，并允许任何副本直接接受来⾃客户端的写⼊。
* Amazon Dynamo, Cassandra, Riak, Voldmort

### 当节点故障时写⼊数据库

#### 读修复和反熵
* Read repair
  * 当客户端并⾏读取多个节点时，它可以检测到任何陈旧的响应。例如，在图5-10中，⽤户2345获得了来⾃Replica 3的版本6值和来⾃副本1和2的版本7值。客户端发现副本3具有陈旧值，并将新值写回复制
品。这种⽅法适⽤于频繁阅读的值。
* Anti-entropy process
  * ⼀些数据存储具有后台进程，该进程不断查找副本之间的数据差异，并将任何缺少的数据从⼀个
副本复制到另⼀个副本。与基于领导者的复制中的复制⽇志不同，此反熵过程不会以任何特定的顺序复
制写⼊，并且在复制数据之前可能会有显着的延迟。

#### 读写的法定⼈数

## 第六章 分区
* 分区的主要目的是为了可扩展性。不同的分区可以放在不共享集群的不同节点上，对于在单个分区上运行的查询，每个节点可以独立执行对自己的查询，因此可以通过添加更多节点来扩大查询吞吐量。

### 分区与复制
* 分区通常与复制结合使用，使得每个分区的副本存储在多个节点上，这意味着即使每条记录属于一个分区，它仍然可以存储在多个不同的节点上以获得容错能力。
* 一个节点可能存储多个分区。如果使用主从复制模型，每个分区领导者被分配给一个节点，追随者(从)被分配给其他节点。每个节点可能是某些分区的领导者，同时是其他分区的追随者。

### 键值数据的分区
* 分区的目标是将数据和查询负载均匀分布在各个节点上，如果每个节点公平分享数据和负载，那么理论上10个节点应该能够处理10倍的数据量和10倍的单个节点的读写吞吐量。
* 如果分区时不均匀的，一些分区比其他分区有更多的数据或查询，那么就有偏斜(skew)。在极端情况下，所有负载可能压在一个分区上，这个分区被称为热点(hot spot)。

#### 根据键的范围分区
* 为每个分区指定一块连续的键范围

#### 根据键的散列分区
* 由于偏斜和热点的风险，许多分布式存储使用散列函数来确定给定键的分区。
* 一致性哈希(consistent hashing)
  * 能均匀分配负载，它是由随机选择的分区边界(partition boundaries)来避免中央控制或分布式一致性的需要。

#### 负载倾斜与消除热点
* 大多数数据库系统无法自动补偿这种高度偏斜的负载，因此应用程序有责任减少偏斜。

### 分片与次级索引
#### 按文档的二级索引
#### 根据关键词的二级索引

### 分区再平衡
* 随着时间推移，数据库会发生变化
  * 查询吞吐量增加，需要添加更多CPU
  * 数据量增加，需要更多RAM和Disk
  * 机器出现故障，需要新机器代替它
* 将负载从集群的一个节点向另一个节点移动的过程称为再平衡。
  * 再平衡之后，负载应该再集群中的节点之间公平地共享
  * 再平衡发生时，数据库应该正常接收读取和写入
  * 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I/O负载

#### 平衡策略
##### 固定数量的分区
* 创建比节点更多的分区，并为每个节点分配多个分区，这样新节点可以从当前每个节点窃取一些分区，直到分区再次公平分配。

##### 动态分区
* 对于是由键范围分区的数据库，具有固定边界的固定数量的分区将非常不便，如果出现边界错误，则可能会导致一个分区中的所有数据或者其他分区的所有数据为空。
* 按键的范围进行分区的数据库会动态创建分区。当分区增长到超过配置的大小时，会被分成两个分区，每个分区约占一半的数据。对应地，数据删除后如果分区缩小到阈值以下，则可以将其与相邻分区合并。与B树Node Merge发生的过程类似。

##### 按节点⽐例分区
* 每个节点具有固定数量的分区。在这种情况下，每个分区的⼤⼩与数据集⼤⼩成⽐例地增⻓，⽽节点数量保持不变，但是当增加节点数时，分区将再次变⼩。由于较⼤的数据量通常需要较⼤数量的节点进⾏存
储，因此这种⽅法也使每个分区的⼤⼩较为稳定。

### 请求路由
* 服务发现
  * 允许客户端连接任何节点，通过轮询的负载均衡。
  * 由一个路由层来负责。
  * 要求客户端知道分区的节点的分配。

#### 执⾏并⾏查询

## 第七章 事务
## 第八章 分布式系统的麻烦
## 第九章 一致性与共识

# 第三部分 衍生数据
* 从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中，当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库、缓存、索引等。
## 第十章 批处理
## 第十一章 流处理
## 第十二章 数据系统的未来